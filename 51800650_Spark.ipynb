{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "51800650_Spark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR1Jel580OJK",
        "outputId": "9eeb73c4-2011-496d-bf8c-bb53230b3086"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOI1UlXG0gym"
      },
      "source": [
        "#Tạo Project trên Colab dùng Spark đọc vào một file văn bản và đếm số từ trên bản, lọc ra k từ có tần suất xuất hiện nhiều nhất."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGAYfUBp0RTH"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext\r\n",
        "import collections\r\n",
        "\r\n",
        "conf= SparkConf().setMaster(\"local\").setAppName(\"word counting\")\r\n",
        "sc= SparkContext.getOrCreate(conf= conf)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDpZzverlX80"
      },
      "source": [
        "import pyspark\r\n",
        "from pyspark import SparkConf,SparkContext\r\n",
        "import collections\r\n",
        "from collections import Counter"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLa3iWPN0dUl",
        "outputId": "8fa2cb8e-0204-431b-a8fa-fbc17e106abd"
      },
      "source": [
        "data_file= sc.textFile(\"/content/text.txt\")\r\n",
        "print(data_file.first())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sự khác biệt giữa Hadoop MapReduce và Spark nằm ở cách tiếp cận xử lý. Spark có thể thực hiện việc đó trong bộ nhớ, trong khi Hadoop MapReduce phải đọc và ghi vào đĩa. Do đó, tốc độ xử lý có sự khác biệt đáng kể - Spark có thể nhanh hơn tới 100 lần. Tuy nhiên, khối lượng dữ liệu được xử lý cũng khác nhau: Hadoop MapReduce có thể làm việc với các tập dữ liệu lớn hơn nhiều so với Spark.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrXOFG63162t"
      },
      "source": [
        "array_file= text_file.first().split(\" \")\r\n",
        "rddd_file= sc.parallelize(array_file)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnRCh2xv5BXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7717a0b4-8c6a-4684-9ec0-3977b0793c27"
      },
      "source": [
        "text=text_file.first().split(\" \")\r\n",
        "rdd= sc.parallelize(text)\r\n",
        "counts= rdd.map(lambda word:(word,1))\r\n",
        "print(counts.collect())"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Sự', 1), ('khác', 1), ('biệt', 1), ('giữa', 1), ('Hadoop', 1), ('MapReduce', 1), ('và', 1), ('Spark', 1), ('nằm', 1), ('ở', 1), ('cách', 1), ('tiếp', 1), ('cận', 1), ('xử', 1), ('lý.', 1), ('Spark', 1), ('có', 1), ('thể', 1), ('thực', 1), ('hiện', 1), ('việc', 1), ('đó', 1), ('trong', 1), ('bộ', 1), ('nhớ,', 1), ('trong', 1), ('khi', 1), ('Hadoop', 1), ('MapReduce', 1), ('phải', 1), ('đọc', 1), ('và', 1), ('ghi', 1), ('vào', 1), ('đĩa.', 1), ('Do', 1), ('đó,', 1), ('tốc', 1), ('độ', 1), ('xử', 1), ('lý', 1), ('có', 1), ('sự', 1), ('khác', 1), ('biệt', 1), ('đáng', 1), ('kể', 1), ('-', 1), ('Spark', 1), ('có', 1), ('thể', 1), ('nhanh', 1), ('hơn', 1), ('tới', 1), ('100', 1), ('lần.', 1), ('Tuy', 1), ('nhiên,', 1), ('khối', 1), ('lượng', 1), ('dữ', 1), ('liệu', 1), ('được', 1), ('xử', 1), ('lý', 1), ('cũng', 1), ('khác', 1), ('nhau:', 1), ('Hadoop', 1), ('MapReduce', 1), ('có', 1), ('thể', 1), ('làm', 1), ('việc', 1), ('với', 1), ('các', 1), ('tập', 1), ('dữ', 1), ('liệu', 1), ('lớn', 1), ('hơn', 1), ('nhiều', 1), ('so', 1), ('với', 1), ('Spark.', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGut-FaJ5DTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0c0b6a-fa3e-4d68-b4ff-ccdaae4fc3d3"
      },
      "source": [
        "words= counts.reduceByKey(lambda x,y: x+y)\r\n",
        "print(words.collect())"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Sự', 1), ('khác', 3), ('biệt', 2), ('giữa', 1), ('Hadoop', 3), ('MapReduce', 3), ('và', 2), ('Spark', 3), ('nằm', 1), ('ở', 1), ('cách', 1), ('tiếp', 1), ('cận', 1), ('xử', 3), ('lý.', 1), ('có', 4), ('thể', 3), ('thực', 1), ('hiện', 1), ('việc', 2), ('đó', 1), ('trong', 2), ('bộ', 1), ('nhớ,', 1), ('khi', 1), ('phải', 1), ('đọc', 1), ('ghi', 1), ('vào', 1), ('đĩa.', 1), ('Do', 1), ('đó,', 1), ('tốc', 1), ('độ', 1), ('lý', 2), ('sự', 1), ('đáng', 1), ('kể', 1), ('-', 1), ('nhanh', 1), ('hơn', 2), ('tới', 1), ('100', 1), ('lần.', 1), ('Tuy', 1), ('nhiên,', 1), ('khối', 1), ('lượng', 1), ('dữ', 2), ('liệu', 2), ('được', 1), ('cũng', 1), ('nhau:', 1), ('làm', 1), ('với', 2), ('các', 1), ('tập', 1), ('lớn', 1), ('nhiều', 1), ('so', 1), ('Spark.', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us2uv_sAOqFv",
        "outputId": "a6ccd742-a34e-4f71-c11b-e5fd0e81ec2c"
      },
      "source": [
        "Counter(text)\r\n",
        "Counter(text).most_common(5)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('có', 4), ('khác', 3), ('Hadoop', 3), ('MapReduce', 3), ('Spark', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDMGN-uoTM3S"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdaoGg3LTPOv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}